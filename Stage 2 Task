# The normal and tumor datasets were downloaded from Zenodo using the wget command.

$ mkdir -p raw_data 
$ cd raw_data
$ wget https://zenodo.org/record/2582555/files/SLGFSK-N_231335_r1_chr5_12_17.fastq.gz 
$ wget https://zenodo.org/record/2582555/files/SLGFSK-N_231335_r2_chr5_12_17.fastq.gz 
$ wget https://zenodo.org/record/2582555/files/SLGFSK-T_231336_r1_chr5_12_17.fastq.gz 
$ wget https://zenodo.org/record/2582555/files/SLGFSK-T_231336_r2_chr5_12_17.fastq.gz 

# The refrence genome (hg 19) was downloaded from Zenodo
$ wget https://zenodo.org/record/2582555/files/hg19.chr5_12_17.fa.gz

#unzip reference
$ unzip hg19.chr5_12_17.fa.gz

# The reads quality were examined using fastqc and an aggregate report generated with multiqc.

#create directory for the fastqc output
$ mkdir -p Fastqc_Reports

#create a file named list.txt 
$ nano list.txt

# the content inside list.txt 
SLGFSK-N_231335 
SLGFSK-T_231336

#Quality control on reads 
for sample in `cat list.txt` 
do 
 fastqc raw_data/${sample}*_r1_chr5_12_17.fastq.gz -o Fastqc_Reports 
done 
 
multiqc Fastqc_Reports -o Fastqc_Reports  

#  Removing low quality sequences using Trimmomatic
$ mkdir -p trimmed_reads

for sample in `cat list.txt`
do
       trimmomatic PE -threads 8 raw_data/${sample}_r1_chr5_12_17.fastq.gz raw_data/${sample}_r2_chr5_12_17.fastq.gz \
               trimmed_reads/${sample}_r1_paired.fq.gz trimmed_reads/${sample}_r1_unpaired.fq.gz \
               trimmed_reads/${sample}_r2_paired.fq.gz trimmed_reads/${sample}_r2_unpaired.fq.gz \
               ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:8:keepBothReads \
               LEADING:3 TRAILING:10 MINLEN:25
       
       fastqc  trimmed_reads/${sample}_r1_paired.fq.gz  trimmed_reads/${sample}_r2_paired.fq.gz \
                 -o trimmed_reads/Fastqc_results
done 

multiqc  trimmed_reads/Fastqc_results  -o trimmed_reads/Fastqc_results

# Read mapping using BWA-MEM
# First, a directory was created for the reference and then copied
$ mkdir reference
$ mv hg19.chr5_12_17.fa reference

#The reference is indexed to be able to align the data
$ bwa index hg19.chr5_12_17.fa 

mkdir Mapping
   
#Perform alignment
bwa mem -R '@RG\tID:231335\tSM:Normal' hg19.chr5_12_17.fa trimmed_reads/SLGFSK-N_231335_r1_paired.fq.gz \
      trimmed_reads/SLGFSK-N_231335_r2_paired.fq.gz > Mapping/SLGFSK-N_231335.sam

bwa mem -R '@RG\tID:231336\tSM:Tumor' hg19.chr5_12_17.fa trimmed_reads/SLGFSK-T_231336_r1_paired.fq.gz \
       trimmed_reads/SLGFSK-T_231336_r2_paired.fq.gz > Mapping/SLGFSK-T_231336.sam	

# Conversion of the SAM file to BAM file, sorting and indexing

for sample in `cat list.txt`
do
        Convert SAM to BAM and sort it 
        samtools view -@ 20 -S -b Mapping/${sample}.sam | samtools sort -@ 32 > Mapping/${sample}.sorted.bam
        
        Index BAM file
        samtools index Mapping/${sample}.sorted.bam
done

# Mapped reads filtering

for sample in `cat list.txt`
do
	#Filter BAM files
        samtools view -q 1 -f 0x2 -F 0x8 -b Mapping/${sample}.sorted.bam > Mapping/${sample}.filtered1.bam
done

# Duplicates removal 
nano markdup.sh 
 
for sample in `cat list.txt`
do
	samtools collate -o Mapping/${sample}.namecollate.bam Mapping/${sample}.filtered1.bam
        samtools fixmate -m Mapping/${sample}.namecollate.bam Mapping/${sample}.fixmate.bam
        samtools sort -@ 32 -o Mapping/${sample}.positionsort.bam Mapping/${sample}.fixmate.bam
        samtools markdup -@32 -r Mapping/${sample}.positionsort.bam Mapping/${sample}.clean.bam
done
	
#or rmdup
samtools rmdup SLGFSK35.sorted.bam  SLGFSK35.rdup and samtools rmdup SLGFSK36.sorted.bam  SLGFSK36.rdup


# Left Align BAM
for sample in `cat list.txt`
do      
        cat Mapping/${sample}.clean.bam  | bamleftalign -f hg19.chr5_12_17.fa -m 5 -c > Mapping/${sample}.leftAlign.bam

#-c - compressed, -m - max-iterations

# Recalibrate read mapping qualities
for sample in `cat list.txt`
do
        samtools calmd -@ 32 -b Mapping/${sample}.leftAlign.bam hg19.chr5_12_17.fa > Mapping/${sample}.recalibrate.bam
done

# Refilter read mapping qualities
for sample in `cat list.txt`
do
        bamtools filter -in Mapping/${sample}.recalibrate.bam -mapQuality <=254 > Mapping/${sample}.refilter.bam
done

# Variant calling and classification

#Convert data to pileup
mkdir Variants

for sample in `cat list.txt`
do
        samtools mpileup -f hg19.chr5_12_17.fa Mapping/${sample}.refilter.bam --min-MQ 1 --min-BQ 28 \
                > Variants/${sample}.pileup
done

# Call variants
varscan somatic Variants/SLGFSK-N_231335.pileup \ 
        Variants/SLGFSK-T_231336.pileup Variants/SLGFSK \ 
        --normal-purity 1  --tumor-purity 0.5 --output-vcf 1
        
 # Merge vcf (VarScan generates 2 outputs (indel.vcf and snp.vcf), merge the two into one vcf file using bcftools)
 
bgzip Variants/SLGFSK.snp.vcf > Variants/SLGFSK.snp.vcf.gz
bgzip Variants/SLGFSK.indel.vcf > Variants/SLGFSK.indel.vcf.gz
tabix Variants/SLGFSK.snp.vcf.gz
tabix Variants/SLGFSK.indel.vcf.gz
bcftools merge Variants/SLGFSK.snp.vcf.gz Variants/SLGFSK.indel.vcf.gz > Variants/SLGFSK.vcf

# Variant Annotation (Functional Annotation using SnpEff)
 $ snpEff hg19 Variants/SLGFSK.vcf > Variants/SLGFSK.ann.vcf 
 
 # Clinical Annotation using gemini
 $ wget https://raw.github.com/arq5x/gemini/master/gemini/scripts/gemini_install.py
python gemini_install.py /usr/local /usr/local/share/gemini

$ gemini load -v Variants/SLGFSK.ann.vcf -t snpEff Annotation/gemini.db







